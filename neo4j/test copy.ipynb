{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'neg': 1.0, 'neu': 0.0, 'pos': 0.0, 'compound': -0.5719}, 'Unique words count: 1')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\zachary\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download(\"vader_lexicon\")\n",
    "\n",
    "\n",
    "def is_memorable(sentence):\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    score = sia.polarity_scores(sentence)\n",
    "    words = word_tokenize(sentence)\n",
    "    unique_words = set(\n",
    "        words\n",
    "    )  # Check for unique words which might make the sentence memorable\n",
    "    return score, \"Unique words count: {}\".format(len(unique_words))\n",
    "\n",
    "\n",
    "# Example usage\n",
    "sentence = \"hate\"\n",
    "print(is_memorable(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Keywords found: []', 'Store in DB: False')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\zachary\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\zachary\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "\n",
    "def should_remember(sentence, important_keywords):\n",
    "    words = word_tokenize(sentence)\n",
    "    filtered_words = [\n",
    "        word for word in words if word.lower() not in stopwords.words(\"english\")\n",
    "    ]\n",
    "    found_keywords = [\n",
    "        word for word in filtered_words if word.lower() in important_keywords\n",
    "    ]\n",
    "    return \"Keywords found: {}\".format(found_keywords), \"Store in DB: {}\".format(\n",
    "        bool(found_keywords)\n",
    "    )\n",
    "\n",
    "\n",
    "# Example usage\n",
    "important_keywords = {\"ocean\", \"memorable\", \"first visit\"}\n",
    "sentence = \"I dislike icecream\"\n",
    "print(should_remember(sentence, important_keywords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2Model\n",
    "import torch\n",
    "\n",
    "# Load a pre-trained model and tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "model = GPT2Model.from_pretrained(\"gpt2\")\n",
    "\n",
    "\n",
    "def is_memorable(sentence, model, tokenizer):\n",
    "    inputs = tokenizer.encode(sentence, return_tensors=\"pt\")\n",
    "    outputs = model(inputs)\n",
    "    logits = outputs.last_hidden_state\n",
    "    memorability_score = torch.sigmoid(\n",
    "        logits.mean()\n",
    "    )  # Example: Convert logits to a memorability score\n",
    "    return memorability_score.item() > 0.5  # Threshold for deciding if memorable\n",
    "\n",
    "\n",
    "# Example usage\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azureaistudio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
